"""
Script pour analyser pourquoi les scores de confidence et rejection sont bas
et proposer des am√©liorations des hyperparam√®tres
"""

def explain_score_calculation():
    """Explique comment les scores sont calcul√©s"""
    print("=" * 80)
    print("ANALYSE : POURQUOI LES SCORES SONT BAS")
    print("=" * 80)
    
    print("\nüìä CALCUL DU SCORE DE CONFIDENCE (ligne 313-332 de multimodal_fusion.py):")
    print("""
    score = (cv_conf * cv_weight_norm) + (nlp_conf * nlp_weight_norm) + (gabarits * gabarits_weight * 0.3)
    
    Exemple avec les poids actuels (config.yaml):
    - cv_weight = 0.5 ‚Üí cv_weight_norm = 0.5 / (0.5 + 0.5) = 0.5
    - nlp_weight = 0.5 ‚Üí nlp_weight_norm = 0.5 / (0.5 + 0.5) = 0.5
    - gabarits_weight = 0.3 ‚Üí mais multipli√© par 0.3 ! (ligne 326)
    
    ‚ö†Ô∏è PROBL√àME 1: Le facteur 0.3 suppl√©mentaire r√©duit trop le poids des gabarits
       gabarits_weight effectif = 0.3 * 0.3 = 0.09 (seulement 9%!)
    
    ‚ö†Ô∏è PROBL√àME 2: Si CV et NLP sont en d√©saccord ou ont des confidences basses:
       Exemple: cv_conf = 0.6, nlp_conf = 0.5
       score = 0.6 * 0.5 + 0.5 * 0.5 = 0.3 + 0.25 = 0.55 (BAS!)
    
    ‚ö†Ô∏è PROBL√àME 3: Si les mod√®les CV ou NLP ne sont pas bien entra√Æn√©s:
       - Le mod√®le CV peut avoir des confidences basses
       - Le mod√®le NLP peut avoir des confidences basses
       - R√©sultat: score final bas
    """)
    
    print("\nüìâ CALCUL DU REJECTION_SCORE (ligne 334-340):")
    print("""
    rejection_score = max(0.0, 1.0 - gap - confidence)
    
    o√π gap = diff√©rence entre le score le plus √©lev√© et le deuxi√®me
    
    ‚ö†Ô∏è PROBL√àME: Si plusieurs classes ont des scores proches:
       Exemple: classe1 = 0.55, classe2 = 0.50
       gap = 0.05
       rejection_score = 1.0 - 0.05 - 0.55 = 0.40 (BAS, mais pas trop mauvais)
       
       Mais si gap est tr√®s petit:
       Exemple: classe1 = 0.52, classe2 = 0.50
       gap = 0.02
       rejection_score = 1.0 - 0.02 - 0.52 = 0.46 (√âLEV√â = ambigu√Øt√©)
    """)
    
    print("\n" + "=" * 80)
    print("SOLUTIONS POUR AM√âLIORER LES SCORES")
    print("=" * 80)
    
    print("\n1. üîß OPTIMISER LES POIDS (Hyperparam√®tres)")
    print("""
    Actuellement dans config.yaml:
    - cv_weight: 0.5
    - nlp_weight: 0.5
    - gabarits_weight: 0.3 (mais effectif = 0.09 √† cause du * 0.3)
    
    Recommandations:
    Option A - Augmenter le poids des gabarits:
      cv_weight: 0.4
      nlp_weight: 0.4
      gabarits_weight: 0.5  # Plus important
    
    Option B - Favoriser le meilleur mod√®le:
      Si CV est meilleur: cv_weight: 0.7, nlp_weight: 0.3
      Si NLP est meilleur: cv_weight: 0.3, nlp_weight: 0.7
    
    Option C - Corriger le facteur 0.3 dans le code:
      Dans multimodal_fusion.py ligne 326, enlever le * 0.3
      score += gabarits_scores[cls] * self.gabarits_weight  # Sans * 0.3
    """)
    
    print("\n2. üéØ AM√âLIORER L'ENTRA√éNEMENT")
    print("""
    - R√©-entra√Æner le mod√®le CV avec plus d'epochs
    - Augmenter la qualit√© des donn√©es d'entra√Ænement
    - Utiliser data augmentation
    - Fine-tuner le mod√®le NLP (CamemBERT)
    """)
    
    print("\n3. üìà NORMALISER LES SCORES")
    print("""
    Le probl√®me actuel: les scores peuvent √™tre < 1.0 m√™me avec de bonnes pr√©dictions
    
    Solution: Normaliser les scores pour qu'ils soient entre 0 et 1
    - Diviser par la somme des poids: score / (cv_weight + nlp_weight + gabarits_weight)
    - Ou utiliser softmax sur les scores
    """)
    
    print("\n4. üîç AM√âLIORER LA FUSION")
    print("""
    Actuellement: simple moyenne pond√©r√©e
    Am√©lioration possible:
    - Utiliser une fusion multiplicative quand CV et NLP sont d'accord
    - Augmenter le poids quand il y a accord parfait
    - R√©duire le poids des gabarits seulement quand ils sont peu fiables
    """)

def propose_improvements():
    """Propose des am√©liorations concr√®tes"""
    print("\n" + "=" * 80)
    print("AM√âLIORATIONS CONCR√àTES RECOMMAND√âES")
    print("=" * 80)
    
    print("\n‚úÖ PRIORIT√â 1: Corriger le facteur 0.3 pour les gabarits")
    print("   Fichier: src/fusion/multimodal_fusion.py, ligne 326")
    print("   Changer: score += gabarits_scores[cls] * self.gabarits_weight * 0.3")
    print("   En:      score += gabarits_scores[cls] * self.gabarits_weight")
    
    print("\n‚úÖ PRIORIT√â 2: Ajuster les poids dans config.yaml")
    print("   Option recommand√©e:")
    print("   fusion:")
    print("     cv_weight: 0.4")
    print("     nlp_weight: 0.4")
    print("     gabarits_weight: 0.5  # Augment√© pour compenser le * 0.3")
    
    print("\n‚úÖ PRIORIT√â 3: Normaliser les scores finaux")
    print("   Ajouter une normalisation pour que les scores soient entre 0 et 1")
    
    print("\n‚úÖ PRIORIT√â 4: Am√©liorer la fusion quand il y a accord")
    print("   Multiplier les scores quand CV et NLP sont d'accord")

if __name__ == "__main__":
    explain_score_calculation()
    propose_improvements()

